import{_ as c}from"./_plugin-vue_export-helper.cdc0426e.js";import{o as d,c as i,a as e,b as t,d as a,w as s,e as r,r as o}from"./app.adeb8394.js";const l={},u=e("h1",{id:"kafka-connector",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#kafka-connector","aria-hidden":"true"},"#"),t(" Kafka connector")],-1),m=r(`<p>The Kafka connector supports the following functional points:</p><ul><li><code>At Least Once</code> write in batch scenarios</li><li><code>Exactly Once</code> read in streaming scenarios</li></ul><h2 id="maven-dependency" tabindex="-1"><a class="header-anchor" href="#maven-dependency" aria-hidden="true">#</a> Maven dependency</h2><p>The Kafka connector internally uses <code>org.apache.kafka:kafka-clients</code> (version 1.0.1) for data writing. So when using kafka to write the connector, you need to pay attention that the target kafka cluster should be able to use this version of kafka-clients.</p><div class="language-xml line-numbers-mode" data-ext="xml"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.bytedance.bitsail<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>bitsail-connector-kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>\${revision}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="kafka-reader" tabindex="-1"><a class="header-anchor" href="#kafka-reader" aria-hidden="true">#</a> Kafka reader</h2><h3 id="parameters" tabindex="-1"><a class="header-anchor" href="#parameters" aria-hidden="true">#</a> Parameters</h3><table><thead><tr><th>Param name</th><th>Required</th><th>Default value</th><th>Description</th></tr></thead><tbody><tr><td>class</td><td>Yes</td><td></td><td>Reader class name for kafka connector,<code>com.bytedance.bitsail.connector.legacy.kafka.source.KafkaSourceFunctionDAGBuilder</code></td></tr><tr><td>child_connector_type</td><td>Yes</td><td></td><td>Only could be <code>kafka</code></td></tr><tr><td>reader_parallelism_num</td><td>No</td><td></td><td>Reader parallelism num</td></tr></tbody></table><h4 id="parameters-for-kafkaconsumer" tabindex="-1"><a class="header-anchor" href="#parameters-for-kafkaconsumer" aria-hidden="true">#</a> Parameters for KafkaConsumer</h4><p>The underlying Kafka connector uses <code>FlinkKafkaConsumer</code> for reading. The properties or kafka information of the initialized FlinkKafkaConsumer are passed in through options <code>job.reader.connector</code>. You can specify them as follows:</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;job&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;reader&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">&quot;connector&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;prop_key&quot;</span><span class="token operator">:</span> <span class="token string">&quot;prop_value&quot;</span>   <span class="token comment">// &quot;prop_key&quot; means property key, while &quot;prop_val&quot; means property value</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>job.reader.connector</code> supports KV configuration in the form of &lt;string,string&gt;, where:</p><ul><li><code>prop_key</code>: FlinkKafkaConsumer property key</li><li><code>prop_value</code>: FlinkKafkaConsumer property key</li></ul><p>Some common property used are listed below:</p><p><b>1. Kafka cluster properties</b></p>`,15),k=e("thead",null,[e("tr",null,[e("th",null,"Property key"),e("th",null,"Required"),e("th",null,"Default value"),e("th",null,"Optional value"),e("th",null,"Description")])],-1),h=e("tr",null,[e("td",null,"connector.bootstrap.servers"),e("td",null,"Yes"),e("td"),e("td"),e("td",null,"kafka cluster address")],-1),f=e("tr",null,[e("td",null,"connector.topic"),e("td",null,"Yes"),e("td"),e("td"),e("td",null,"topic to read")],-1),b={href:"http://connector.group.id",target:"_blank",rel:"noopener noreferrer"},g=e("td",null,"Yes",-1),v=e("td",null,null,-1),y=e("td",null,null,-1),_=e("td",null,"kafka consumer group",-1),q=r(`<p><b>2. Where to start consuming</b></p><table><thead><tr><th>Property key</th><th>Is necessary</th><th>Default value</th><th>Optional value</th><th>Description</th></tr></thead><tbody><tr><td>connector.startup-mode</td><td>No</td><td>group-offsets</td><td>1. <code>ealiest-offset</code>: Consume from the earliest offset of the partition<br>2. <code>latest-offset</code>: Consume from the latest offset of the partition<br>3. <code>group-offsets</code>: Comsume from the offset of the current consumer group<br>4. <code>specific-offsets</code>: Specify the offset for each partition, cooperate with <code>connector.specific-offsets</code><br>5. <code>specific-timestamp</code>: Consume messages after a certain point in time, cooperate with <code>connector.specific-timestamp</code></td><td>Decide from which offsets to consume</td></tr><tr><td>connector.specific-offsets</td><td>No</td><td></td><td></td><td>Used with specific-offsets, the format is a standard json string.<br>For example:<br><code>[{&quot;partition&quot;:1,&quot;offset&quot;:100},{&quot;partition&quot;:2,&quot;offset&quot;:200}]</code></td></tr><tr><td>connector.specific-timestamp</td><td>No</td><td></td><td></td><td>Used with specific-timestamp (ms) to specify the offset to consume</td></tr></tbody></table><p><b>3. Other FlinkKafkaConsumer parameters</b></p><p>FlinkKafkaConsumer supports many parameters, please refer to <a href="https://kafka.apache.org/21/javadoc/?org/apache/kafka/clients/consumer/ConsumerConfig.html">ConsumerConfig(2.1.0) API]</a> for details . If the user needs to set these parameters, it can be configured through <code>connector.XXX</code>.</p><p>For example, to set MAX_PARTITION_FETCH_BYTES_CONFIG to 1024, add the parameter:</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;job&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;reader&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">&quot;connector&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;connector.max.partition.fetch.bytes&quot;</span><span class="token operator">:</span> <span class="token string">&quot;1024&quot;</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="parameters-for-debugging" tabindex="-1"><a class="header-anchor" href="#parameters-for-debugging" aria-hidden="true">#</a> Parameters for debugging</h4><p>The Kafka read connector is used in streaming scenarios and will be consumed all the time under normal circumstances. If the user wants to debug by consuming only a limited amount of data, the following parameters can be configured. Note that these parameters need to be added to <code>job.reader</code> block.</p><table><thead><tr><th>Property key</th><th>Is necessary</th><th>Default value</th><th>Description</th></tr></thead><tbody><tr><td>enable_count_mode</td><td>No</td><td>false</td><td>Whether to end the current task after sending a piece of data, generally used for testing</td></tr><tr><td>count_mode_record_threshold</td><td>No</td><td>10000</td><td>If <code>enable_count_mode=true</code>, the current task ends after consuming <code>count_mode_record_threshold</code> pieces of messages</td></tr><tr><td>count_mode_run_time_threshold</td><td>No</td><td>600</td><td>If <code>enable_count_mode=true</code>, end the current task after running <code>count_mode_record_threshold</code> seconds</td></tr></tbody></table><h3 id="supported-message-parsing-modes" tabindex="-1"><a class="header-anchor" href="#supported-message-parsing-modes" aria-hidden="true">#</a> Supported message parsing modes</h3><p>Messages can be pulled from KafkaConsumer in format of ConsumerRecord. <strong>BitSail</strong> supports two ways to handle ConsumerRecordof. The user can use <code>job.reader.format</code> to decide which method to use.</p><ul><li><code>job.reader.format_type=&quot;json&quot;</code>: Parse according to json format <ul><li>In this mode, <strong>BitSail</strong> parses the json format string represented by value in ConsumerRecord according to the parameters <code>job.reader.columns</code> set by the user.</li><li>Therefore, the parameters <code>job.reader.columns</code> is required in this mode</li></ul></li><li><code>job.reader.format_type=&quot;streaming_file&quot;</code>: Use raw byte value <ul><li>In this mode, <strong>BitSail</strong> directly deliver the raw bytes value in ConsumerRecord. The specific structure is as follows:</li></ul></li></ul><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code>   <span class="token punctuation">[</span>
    <span class="token punctuation">{</span><span class="token property">&quot;index&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;key&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;binary&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>     <span class="token comment">// message key</span>
    <span class="token punctuation">{</span><span class="token property">&quot;index&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;value&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;binary&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>   <span class="token comment">// message value</span>
    <span class="token punctuation">{</span><span class="token property">&quot;index&quot;</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;partition&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;string&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment">// partition of the message</span>
    <span class="token punctuation">{</span><span class="token property">&quot;index&quot;</span><span class="token operator">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;offset&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;long&quot;</span><span class="token punctuation">}</span>     <span class="token comment">// offset of the meesage in partition</span>
   <span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="kafka-writer" tabindex="-1"><a class="header-anchor" href="#kafka-writer" aria-hidden="true">#</a> Kafka Writer</h2><h3 id="parameters-1" tabindex="-1"><a class="header-anchor" href="#parameters-1" aria-hidden="true">#</a> Parameters</h3><p>Note that these parameters should be added to <code>job.writer</code> block.</p><h4 id="necessary-parameters" tabindex="-1"><a class="header-anchor" href="#necessary-parameters" aria-hidden="true">#</a> Necessary parameters</h4><table><thead><tr><th>Param names</th><th>Default value</th><th>Description</th></tr></thead><tbody><tr><td>class</td><td></td><td>Writer class name of kafka connector, <code>com.bytedance.bitsail.connector.legacy.kafka.sink.KafkaOutputFormat</code></td></tr><tr><td>kafka_servers</td><td></td><td>Kafka&#39;s bootstrap server address, multiple bootstrap server addresses are separated by <code>&#39;,&#39;</code></td></tr><tr><td>topic_name</td><td></td><td>kafka topic</td></tr><tr><td>columns</td><td></td><td>Describing fields&#39; names and data types</td></tr></tbody></table><h4 id="optional-parameters" tabindex="-1"><a class="header-anchor" href="#optional-parameters" aria-hidden="true">#</a> Optional parameters</h4><table><thead><tr><th>Param names</th><th>Default value</th><th>Description</th></tr></thead><tbody><tr><td>writer_parallelism_num</td><td></td><td>writer parallelism num</td></tr><tr><td>partition_field</td><td></td><td><code>partition_field</code> contains one or several fields from <code>job.writer.columns</code>, separated by commas (<i>e.g.</i> &quot;id,timestamp&quot;). If partition_field is not empty, when sending data to kafka topic, it will decide which topic to write based on the hash values ​​of these fields in the record</td></tr><tr><td>log_failures_only</td><td>false</td><td>When KafkaProducer fails to perform an asynchronous send operation:<br> 1. If <code>log_failures_only=true</code>, only log failure information<br> 2. If <code>log_failures_only=false</code>, throw an exception</td></tr><tr><td>retries</td><td>10</td><td>Number of failed retries for KafkaProducer</td></tr><tr><td>retry_backoff_ms</td><td>1000</td><td>KafkaProducer&#39;s failure retry interval (ms)</td></tr><tr><td>linger_ms</td><td>5000</td><td>The maximum waiting time (ms) for KafkaProducer to create a single batch</td></tr></tbody></table><h4 id="other-parameters" tabindex="-1"><a class="header-anchor" href="#other-parameters" aria-hidden="true">#</a> Other parameters</h4><p>When initializing the KafkaProducer, the user can use <code>job.common.optional</code> to pass initialization parameters, for example:</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
   <span class="token property">&quot;job&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">&quot;common&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
         <span class="token property">&quot;optional&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;batch.size&quot;</span><span class="token operator">:</span> <span class="token number">16384</span><span class="token punctuation">,</span>
            <span class="token property">&quot;buffer.memory&quot;</span><span class="token operator">:</span> <span class="token number">33554432</span>
         <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
   <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="related-documents" tabindex="-1"><a class="header-anchor" href="#related-documents" aria-hidden="true">#</a> Related documents</h2>`,24);function x(w,j){const n=o("RouterLink"),p=o("ExternalLinkIcon");return d(),i("div",null,[u,e("p",null,[t("Parent document: "),a(n,{to:"/en/documents/connectors/"},{default:s(()=>[t("Connectors")]),_:1})]),m,e("table",null,[k,e("tbody",null,[h,f,e("tr",null,[e("td",null,[e("a",b,[t("connector.group.id"),a(p)])]),g,v,y,_])])]),q,e("p",null,[t("Configuration examples: "),a(n,{to:"/en/documents/connectors/kafka/kafka-example.html"},{default:s(()=>[t("Kafka connector example")]),_:1})])])}const I=c(l,[["render",x],["__file","kafka.html.vue"]]);export{I as default};
